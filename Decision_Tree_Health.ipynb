{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Trees_Quantified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8225529705540584\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.02      0.04     28301\n",
      "        Good       0.82      1.00      0.90    156767\n",
      "        Poor       0.97      0.56      0.71     17167\n",
      "\n",
      "    accuracy                           0.82    202235\n",
      "   macro avg       0.73      0.53      0.55    202235\n",
      "weighted avg       0.77      0.82      0.76    202235\n",
      "\n",
      "          Feature  Importance\n",
      "24          stump    0.449791\n",
      "25           dead    0.370139\n",
      "3      brch_other    0.054063\n",
      "34   Norway maple    0.033098\n",
      "6      trnk_other    0.027491\n",
      "..            ...         ...\n",
      "57         cherry    0.000000\n",
      "56      sassafras    0.000000\n",
      "55   crepe myrtle    0.000000\n",
      "54    Douglas-fir    0.000000\n",
      "148        mimosa    0.000000\n",
      "\n",
      "[149 rows x 2 columns]\n",
      "Accuracy: 0.8216678616461047\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.00      0.00     28301\n",
      "        Good       0.81      1.00      0.90    156767\n",
      "        Poor       1.00      0.55      0.71     17167\n",
      "\n",
      "    accuracy                           0.82    202235\n",
      "   macro avg       0.74      0.52      0.54    202235\n",
      "weighted avg       0.77      0.82      0.76    202235\n",
      "\n",
      "Feature Importance:\n",
      "                    Feature  Importance\n",
      "24                   stump    0.449791\n",
      "25                    dead    0.370139\n",
      "3               brch_other    0.054063\n",
      "34            Norway maple    0.033098\n",
      "6               trnk_other    0.027491\n",
      "..                     ...         ...\n",
      "143      Japanese hornbeam    0.000000\n",
      "144                   pine    0.000000\n",
      "145  two-winged silverbell    0.000000\n",
      "146          false cypress    0.000000\n",
      "148                 mimosa    0.000000\n",
      "\n",
      "[149 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_species = df['spc_common'].unique() \n",
    "species_columns = [col for col in df.columns if col in unique_species]\n",
    "\n",
    "df['health'] = pd.cut(df['health'], bins=[-0.1, 0.4, 0.6, 1.1], labels=['Poor', 'Fair', 'Good'])\n",
    "selected_columns = [\n",
    "    'tree_dbh', 'cncldist', 'st_assem', 'brch_other', \n",
    "    'brch_shoe', 'brch_light', 'trnk_other', 'trnk_light', 'trunk_wire', 'root_other', \n",
    "    'root_grate', 'root_stone', 'sidewalk', 'guards', 'steward']+ species_columns\n",
    "X = df[selected_columns]\n",
    "y = df['health']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance_df)\n",
    "\n",
    "y_pred_all0 = clf.predict(X)\n",
    "df['dt_predicted_health'] = y_pred_all0\n",
    "\n",
    "#random forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=10)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred1))\n",
    "\n",
    "importances1 = rf_clf.feature_importances_\n",
    "feature_importance_df1 = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "feature_importance_df1 = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature Importance:\\n\", feature_importance_df1)\n",
    "\n",
    "y_pred_all1 = rf_clf.predict(X)\n",
    "df['rf_predicted_health'] = y_pred_all1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Mean Squared Error: 0.22767089739755542\n",
      "DT R^2 Score: 0.40643310307058844\n",
      "RF Mean Squared Error: 0.22609793849866588\n",
      "RF R^2 Score: 0.4105340063625056\n"
     ]
    }
   ],
   "source": [
    "#mse and r^2 calculations\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "label_mapping = {'Poor': 0, 'Fair': 1, 'Good': 2}\n",
    "df['health_numeric'] = df['health'].map(label_mapping)\n",
    "\n",
    "y = df['health_numeric']\n",
    "X = df[selected_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "reg = DecisionTreeRegressor(random_state=42, max_depth=10)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"DT Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"DT R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "reg = RandomForestRegressor(random_state=42, max_depth=10)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"RF Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"RF R^2 Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data redimensions for showing in the graph\n",
    "df.loc[df['rf_predicted_health'].isin(['Poor']), ['rf_predicted_health']] = 0\n",
    "df.loc[df['rf_predicted_health'] == 'Fair', ['rf_predicted_health']] = 0.5\n",
    "df.loc[df['rf_predicted_health']== 'Good', ['rf_predicted_health']] = 1\n",
    "\n",
    "df['health'] = df['health'].cat.add_categories([0, 0.5, 1])\n",
    "\n",
    "df.loc[df['health'] == 'Poor', ['health']] = 0\n",
    "df.loc[df['health'] == 'Fair', ['health']] = 0.5\n",
    "df.loc[df['health'] == 'Good', ['health']] = 1\n",
    "\n",
    "df.loc[df['borough'] == 1, ['borough']] = ['Brooklyn']\n",
    "df.loc[df['borough'] == 2, ['borough']] = ['Manhattan']\n",
    "df.loc[df['borough'] == 3, ['borough']] = ['Queens']\n",
    "df.loc[df['borough'] == 0, ['borough']] = ['Bronx']\n",
    "df.loc[df['borough'] == 4, ['borough']] = ['Staten Island']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            739\n",
      "1            973\n",
      "2            449\n",
      "3            449\n",
      "4            165\n",
      "           ...  \n",
      "674110       519\n",
      "674111       707\n",
      "674112       201\n",
      "674113    235.02\n",
      "674114      1341\n",
      "Name: census tract, Length: 674115, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function to modify the census tract based on its length\n",
    "df['census tract'] = df['census tract'].astype(str).str.replace('.00', '', regex=True)\n",
    "def striging(census):\n",
    "    modified_tracts = []\n",
    "    for part in census:\n",
    "        part1 = str(part)\n",
    "        part_no = part1\n",
    "        if part1[len(part1)-2]=='.':\n",
    "            part_no = part_no[:len(part1)-2]\n",
    "        modified_tracts.append(part_no)\n",
    "    return modified_tracts\n",
    "\n",
    "df['census tract'] = striging(df['census tract'])\n",
    "print(df['census tract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('DecisionTree_RandomForest_Health_Predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional Test do not run, just see results were used to optimize hyperparameters DO NOT RUN WILL JUST TAKE TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8213019507009173\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.04      0.08     28301\n",
      "        Good       0.82      0.99      0.90    156767\n",
      "        Poor       0.95      0.57      0.71     17167\n",
      "\n",
      "    accuracy                           0.82    202235\n",
      "   macro avg       0.72      0.53      0.56    202235\n",
      "weighted avg       0.77      0.82      0.77    202235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Additional Test do not run, just see results\n",
    "X = df[selected_columns]\n",
    "y = df['health']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8220980542438252\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.46      0.00      0.01     28301\n",
      "        Good       0.81      1.00      0.90    156767\n",
      "        Poor       0.99      0.55      0.71     17167\n",
      "\n",
      "    accuracy                           0.82    202235\n",
      "   macro avg       0.75      0.52      0.54    202235\n",
      "weighted avg       0.78      0.82      0.76    202235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Additional Test do not run, just see results\n",
    "X = df[selected_columns]\n",
    "y = df['health']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8215689667960541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mattias A S Larsson\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Mattias A S Larsson\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.00      0.00      0.00     28301\n",
      "        Good       0.81      1.00      0.90    156767\n",
      "        Poor       1.00      0.55      0.71     17167\n",
      "\n",
      "    accuracy                           0.82    202235\n",
      "   macro avg       0.60      0.52      0.53    202235\n",
      "weighted avg       0.72      0.82      0.76    202235\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mattias A S Larsson\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Additional Test do not run, just see results\n",
    "X = df[selected_columns]\n",
    "y = df['health']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8225084678715356\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.03      0.05     28301\n",
      "        Good       0.82      1.00      0.90    156767\n",
      "        Poor       0.98      0.55      0.71     17167\n",
      "\n",
      "    accuracy                           0.82    202235\n",
      "   macro avg       0.74      0.53      0.55    202235\n",
      "weighted avg       0.77      0.82      0.76    202235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df[selected_columns]\n",
    "y = df['health']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42, max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
